{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "The model 'T5ForConditionalGeneration' is not supported for text-generation. Supported models are ['AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DiffLlamaForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# ✅ 1. Install and Import\n",
    "# ---------------------------------------------\n",
    "!pip install transformers --quiet\n",
    "\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load reasoning model\n",
    "model_name = \"MBZUAI/LaMini-Flan-T5-783M\"\n",
    "lamini_pipe = pipeline(\"text2text-generation\", model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# ✅ 2. Define Topics for Claim Generation\n",
    "# ---------------------------------------------\n",
    "topics = [\n",
    "    \"vaccination\", \"heart disease\", \"hydration\", \"mental health\", \"gut health\",\n",
    "    \"diabetes\", \"nutrition\", \"antibiotics\", \"fertility\", \"cancer prevention\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:30<00:00,  9.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 10 total claims.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# ✅ 3. Generate Claims for Each Topic\n",
    "# ---------------------------------------------\n",
    "def generate_claims(topic):\n",
    "    prompt = f\"Generate 3 healthcare claims about {topic}, some true and some false.\"\n",
    "    output = lamini_pipe(prompt, max_length=128, do_sample=True, temperature=0.9)[0][\"generated_text\"]\n",
    "    claims = [c.strip(\"•- \") for c in output.split(\"\\n\") if c.strip()]\n",
    "    return claims\n",
    "\n",
    "all_claims = []\n",
    "for topic in tqdm(topics):\n",
    "    all_claims.extend(generate_claims(topic))\n",
    "\n",
    "print(f\"Generated {len(all_claims)} total claims.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:18<00:00,  7.80s/it]\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# ✅ 4. Assign Credibility + Generate Explanations\n",
    "# ---------------------------------------------\n",
    "def assign_score():\n",
    "    # Evenly sample across bins: 10%, 30%, 50%, 70%, 90%\n",
    "    return random.choice([10, 30, 50, 70, 90])\n",
    "\n",
    "synthetic_data = []\n",
    "\n",
    "for claim in tqdm(all_claims):\n",
    "    score = assign_score()\n",
    "    reasoning_type = \"accurate\" if score > 70 else \"misinformation\"\n",
    "    prompt = f\"Claim: {claim}\\nCredibility: {score}%\\nExplain why this claim is likely {reasoning_type}.\"\n",
    "    explanation = lamini_pipe(prompt, max_length=100, do_sample=False)[0][\"generated_text\"]\n",
    "\n",
    "    synthetic_data.append({\n",
    "        \"claim\": claim,\n",
    "        \"credibility\": score,\n",
    "        \"explanation\": explanation.strip()\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved synthetic_claim_explanations.csv with shape: (10, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>credibility</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True: Vaccination has been proven to save mill...</td>\n",
       "      <td>50</td>\n",
       "      <td>This claim is likely misinformation because va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1. True: Heart disease is a common health issu...</td>\n",
       "      <td>50</td>\n",
       "      <td>This claim is likely misinformation because he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1. True: Drinking enough water can improve ove...</td>\n",
       "      <td>90</td>\n",
       "      <td>The claim is likely accurate because it is a w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1. Mental health is a complex issue that can b...</td>\n",
       "      <td>30</td>\n",
       "      <td>This claim is likely misinformation because it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True: There is evidence to suggest that gut he...</td>\n",
       "      <td>30</td>\n",
       "      <td>This claim is likely misinformation because it...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim  credibility  \\\n",
       "0  True: Vaccination has been proven to save mill...           50   \n",
       "1  1. True: Heart disease is a common health issu...           50   \n",
       "2  1. True: Drinking enough water can improve ove...           90   \n",
       "3  1. Mental health is a complex issue that can b...           30   \n",
       "4  True: There is evidence to suggest that gut he...           30   \n",
       "\n",
       "                                         explanation  \n",
       "0  This claim is likely misinformation because va...  \n",
       "1  This claim is likely misinformation because he...  \n",
       "2  The claim is likely accurate because it is a w...  \n",
       "3  This claim is likely misinformation because it...  \n",
       "4  This claim is likely misinformation because it...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# ✅ 5. Save Synthetic Data to CSV\n",
    "# ---------------------------------------------\n",
    "df = pd.DataFrame(synthetic_data)\n",
    "df.to_csv(\"synthetic_claim_explanations.csv\", index=False)\n",
    "\n",
    "print(\"Saved synthetic_claim_explanations.csv with shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📘 1. Install and Import Libraries\n",
    "\n",
    "!pip install transformers tqdm --quiet\n",
    "\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# 📘 2. Load Reasoning Model\n",
    "# Load LaMini-Flan reasoning model\n",
    "model_name = \"MBZUAI/LaMini-Flan-T5-248M\"\n",
    "reasoning_pipeline = pipeline(\"text2text-generation\", model=model_name, device=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📘 3. Generate 100 Prompts\n",
    "# Create 100 prompts for the model to expand on\n",
    "base_prompts = [\n",
    "    \"The claim is that exercise helps prevent heart disease.\",\n",
    "    \"The claim is that vaccines are effective at preventing illness.\",\n",
    "    \"The claim is that meditation reduces anxiety.\",\n",
    "    \"The claim is that regular sleep improves brain function.\",\n",
    "    \"The claim is that sunscreen prevents skin cancer.\",\n",
    "    \"The claim is that fiber helps with digestion.\",\n",
    "    \"The claim is that drinking water supports kidney health.\",\n",
    "    \"The claim is that low sodium intake benefits blood pressure.\",\n",
    "    \"The claim is that probiotics support gut health.\",\n",
    "    \"The claim is that dental hygiene impacts heart health.\",\n",
    "    # Repeat and randomly vary structure\n",
    "]\n",
    "# Pad out to 100 with variations\n",
    "while len(base_prompts) < 100:\n",
    "    health_topic = random.choice([\n",
    "        \"exercise\", \"hydration\", \"mental health\", \"nutrition\",\n",
    "        \"disease prevention\", \"vaccination\", \"chronic illness\", \"cancer prevention\"\n",
    "    ])\n",
    "    action = random.choice([\n",
    "        \"helps with\", \"is important for\", \"is linked to\", \"is known to reduce\", \"supports\"\n",
    "    ])\n",
    "    outcome = random.choice([\n",
    "        \"heart health\", \"reduced stress\", \"stronger immunity\", \"lower cancer risk\",\n",
    "        \"lower blood pressure\", \"improved sleep\", \"gut health\"\n",
    "    ])\n",
    "    prompt = f\"The claim is that {health_topic} {action} {outcome}.\"\n",
    "    base_prompts.append(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Generating explanations for synthetic claims...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:12<00:00,  2.52s/it]\n"
     ]
    }
   ],
   "source": [
    "# 📘 4. Generate Explanations\n",
    "# Generate explanations\n",
    "claims = []\n",
    "explanations = []\n",
    "\n",
    "print(\"🧠 Generating explanations for synthetic claims...\")\n",
    "for claim_text in tqdm(base_prompts):\n",
    "    # Strip down to clean claim for CSV\n",
    "    clean_claim = claim_text.replace(\"The claim is that \", \"\").strip().rstrip(\".\")\n",
    "\n",
    "    # Make the prompt explicit for explanation\n",
    "    prompt = f\"Claim: {clean_claim}\\nCredibility: 90%\\nExplain why this claim is likely accurate.\"\n",
    "\n",
    "    output = reasoning_pipeline(prompt, max_length=150, num_return_sequences=1)[0][\"generated_text\"]\n",
    "\n",
    "    claims.append(clean_claim)\n",
    "    explanations.append(output.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📘 5. Assign Scores and Clean Claim Text\n",
    "# Assign credibility scores and clean prompts\n",
    "clean_claims = [c.replace(\"The claim is that \", \"\").strip().rstrip(\".\") for c in claims]\n",
    "scores = [random.randint(71, 95) for _ in range(len(clean_claims))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📘 6. Combine into DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"claim\": clean_claims,\n",
    "    \"score\": scores,\n",
    "    \"explanation\": explanations\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 100+ synthetic claims to 'synthetic_claim_explanations.csv'\n"
     ]
    }
   ],
   "source": [
    "# 📘 7. Save to CSV\n",
    "df.to_csv(\"synthetic_claim_explanations.csv\", index=False)\n",
    "print(\"✅ Saved 100+ synthetic claims to 'synthetic_claim_explanations.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
